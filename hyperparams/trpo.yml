# Note: OpenAI uses 16 mpi workers for training on atari
# in practice, it is run with with 4 workers
atari:
  n_timesteps: !!float 1e7
  policy: 'CnnPolicy'
  timesteps_per_batch: 512
  max_kl: 0.01
  cg_iters: 10
  cg_damping: !!float 1e-3
  entcoeff: 0.0
  gamma: 0.99
  lam: 0.98
  vf_iters: 3
  vf_stepsize: !!float 1e-4

BreakoutNoFrameskip-v4:
  n_timesteps: !!float 1e7
  policy: 'CnnPolicy'
  timesteps_per_batch: 128
  max_kl: 0.001
  cg_iters: 10
  cg_damping: !!float 1e-3
  entcoeff: 0.01
  gamma: 0.99
  lam: 0.98
  vf_iters: 3
  vf_stepsize: !!float 1e-4

Pendulum-v0:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  max_kl: 0.001
  lam: 0.92

MountainCar-v0:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'

# Tuned
MountainCarContinuous-v0:
  n_timesteps: !!float 1.2e5
  policy: 'MlpPolicy'
  max_kl: 1.77e-06
  timesteps_per_batch: 32
  entcoeff: 0.0
  cg_iters: 20
  lam: 0.95
  gamma: 0.9999
  cg_damping: 0.0002
  vf_iters: 10
  vf_stepsize: !!float 0.0463

CartPole-v1:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  timesteps_per_batch: 512
  max_kl: 0.001
  cg_iters: 10
  cg_damping: !!float 1e-3
  entcoeff: 0.0
  gamma: 0.99
  lam: 1
  vf_iters: 3
  vf_stepsize: !!float 1e-4

LunarLander-v2:
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  timesteps_per_batch: 1024
  max_kl: 0.01
  cg_iters: 10
  cg_damping: 0.1
  entcoeff: 0.0
  gamma: 0.99
  lam: 0.98
  vf_iters: 5
  vf_stepsize: !!float 1e-3

LunarLanderContinuous-v2:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  timesteps_per_batch: 1024
  max_kl: 0.01
  cg_iters: 10
  cg_damping: 0.1
  entcoeff: 0.0
  gamma: 0.99
  lam: 0.98
  vf_iters: 5
  vf_stepsize: !!float 1e-3

# 1 env
HalfCheetahBulletEnv-v0:
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  timesteps_per_batch: 4096
  max_kl: 0.05
  cg_iters: 10
  cg_damping: 0.1
  entcoeff: 0.0
  gamma: 0.99
  lam: 0.95
  vf_iters: 5
  vf_stepsize: !!float 1e-3
